{"title":"<p style=\"color:black,text-align:center\">Simple Linear Regresson</p>","markdown":{"yaml":{"title":"<p style=\"color:black,text-align:center\">Simple Linear Regresson</p>","author":"Daniella Ojekere","format":{"html":{"toc-location":"right","toc":true,"toc-title":"Outline","toc-depth":3,"toc_float":null,"collapsed":true,"smooth_scroll":true,"code_folding":"show"}}},"headingText":"[ **SIMPLE LINEAR REGRESSION**]{style=\"color: #16a085;\"}","containsRefs":false,"markdown":"\n\n\n\nOn the target-predictor graph, regression displays a line or curve that traverses each data point in a way that minimizes the vertical distance between the data points and the regression line. A statistical method for simulating the relationship between a dependent variable and a specified collection of independent variables is called linear regression. A linear regression describes the relationship between variables using a straight line. In simple terms, linear regression is a way to understand the relationship between two things (variables). The value of the regression coefficients that minimizes the models overall error determines the line of best fit in the data. Types of Linear Regression\n\nThere are two types of linear regression, Simple linear regression and multiple linear regression. Our discussion in this series will be on simple linear regression using R.\n\n## [**Assumptions of Simple Linear Regression**]{style=\"color: #2C6D26;\"}\n\nThe assumptions of simple linear regressions are:\n\n1.  **L**inearity: Ensure there is a linear relationship between the independent (X) and dependent variable(Y), a straight line represents the line that best fits the data points.\n\n2.  **I**ndependence: The independent and dependent variables have a linear relationship. This indicates that when one variable changes, the other variable changes proportionately.\n\n3.  **N**ormality: The errors are normally distributed\n\n4.  **E**quality of variance: The variability of the response does not increase as the value of the predictor increases. Case Study\n\n**LINE** is a simple acroynm for remembering the assumptions of simple linear regression.\n\n## [**Example**]{style=\"color: #2C6D26;\"}\n\nIn this example, we will be using a dataset on medical insurance cost. The dataset consists of information about the insurance buyers such as age, sex, BMI (body mass index), number of children, smoking habits and region. These variables serve as independent features, while the medical charges represent the dependent feature. The goal is to predict the medical charges based on the age of the individual.\n\n### [**Install packages**]{style=\"color: #138d75;\"}\n\n```{r setup, warning=FALSE, message=FALSE}\ninstall.packages(\"tidyverse\") \ninstall.packages(\"readxl\") \n```\n\n### [**Load the installed packages**]{style=\"color: #138d75;\"}\n\n```{r, warning = FALSE, message = FALSE}\nlibrary(tidyverse) \nlibrary(readxl)\n```\n\n### [**Load the datasets**]{style=\"color: #138d75;\"}\n\n```{r, warning = FALSE, message = FALSE}\nmedical_cost <- read_csv(\"insurance.csv\")\n```\n\n## [**Data Exploration**]{style=\"color: #2C6D26;\"}\n\n### [ **List structure of the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\nstr(medical_cost)\n```\n\n### [ **Summary of the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\nsummary(medical_cost)\n```\n\n### [ **Check the names in the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\nnames(medical_cost)\n```\n\n### [ **Check the number of rows**]{style=\"color: #138d75;\"}\n\n```{r}\nnrow(medical_cost)\n```\n\n### [ **Check number of columns**]{style=\"color: #138d75;\"}\n\n```{r}\nncol(medical_cost)\n```\n\n### [ **See first 6 rows of the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\nhead(medical_cost)\n```\n\n### [ **Check the last 6 rows of the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\ntail(medical_cost)\n```\n\n### [ **Rename sex variable to gender**]{style=\"color: #138d75;\"}\n\n```{r}\nmedical_cost <- medical_cost |>   \n  mutate(across(c(sex: region ), as.factor)) |>   \n  rename(gender = sex)\n```\n\n### [ **Check for missing values**]{style=\"color: #138d75;\"}\n\n```{r}\nsum(is.na(medical_cost))\n```\n\n### [ **Check for duplicates**]{style=\"color: #138d75;\"}\n\n```{r}\nsum(duplicated(medical_cost))\n```\n\nThere is one duplicate, so we drop the duplicate value and work with the unique values\n\n```{r} #Remove duplicates}\nmedical_cost <- medical_cost[!duplicated(medical_cost),]\n```\n\nThe dataset changes from 1338 to 1337 because the duplicate value has been removed.\n\nSince this is a simple linear regression, I will be checking how the age of a patient affects the hospital charges.\n\n### [ **Visualizing the distribution of the age variable**]{style=\"color: #138d75;\"}\n\n```{r}\nage_plot <- ggplot(medical_cost, aes(x = age)) +  \n  geom_histogram(fill = \"steelblue\", color = \"black\", bins = 10) +  \n  labs(title = \"Distribution of Age\", x = \"Age\", y = \"Frequency\")  \n\ninteractive_plot <- plotly::ggplotly(age_plot) \ninteractive_plot\n```\n\n## [ **Checking if it meets up the Assumptions**]{style=\"color:  #2C6D26;\"}\n\n### [ **1. Linearity**]{style=\"color: #138d75;\"}\n\n```{r}\nplot(charges ~ age, data = medical_cost)\n```\n\nThis shows the linearity of age against charges.\n\n### [ **2. Independence** ]{style=\"color: #138d75;\"}\n\n```{r}\ncor(medical_cost$age, medical_cost$charges)  \n```\n\nThe correlation between age and charges is 0.3 which is not close to 1 or -1. This shows that the variables are independent of each other.\n\n**3. Normality and Homoscedasticity will be tested after fitting the model.**\n\n### [ **Fitting the regression model** ]{style=\"color: #138d75;\"}\n\n```{r}\nmodel <- lm(charges ~ age, data = medical_cost)\nmodel\n```\n\n```{r}\nsummary(model)\n```\n\n```{r}\nplot(model)\n```\n\nThe Q-Q residuals shows non-normality of the residuals.Hence, the dependent variable will be transformed to log to see if it will improve the normality of the residuals.\n\n```{r}\nmodel2 <- lm(log(charges) ~ age, data = medical_cost) \nmodel2\n```\n\n```{r}\nsummary(model2)\n```\n\nThe estimated effect of age on charges is 0.034. This means that for every one unit increase in age, the charges increases by 0.034. The p-value is less than 0.05 which means that the effect of age on charges is statistically significant. The R-squared value is 0.09 which means that 9% of the variation in charges can be explained by age. The standard error of the estimate is 0.1, with t value of 22.65 which means that the model is a good fit.\n\n```{r}\nplot(model2)\n```\n\nThe Residual vs Fitted shows that the residuals are homoscedastic and linear, and the Q-Q residuals shows that the residuals are normally distributed.\n\nTherefore, fitting the regression model with the log of charges is a better fit. The regression equation is given as: Charges = 0.034\\*age + 7.5\n","srcMarkdownNoYaml":"\n\n### \n\n# [ **SIMPLE LINEAR REGRESSION**]{style=\"color: #16a085;\"}\n\nOn the target-predictor graph, regression displays a line or curve that traverses each data point in a way that minimizes the vertical distance between the data points and the regression line. A statistical method for simulating the relationship between a dependent variable and a specified collection of independent variables is called linear regression. A linear regression describes the relationship between variables using a straight line. In simple terms, linear regression is a way to understand the relationship between two things (variables). The value of the regression coefficients that minimizes the models overall error determines the line of best fit in the data. Types of Linear Regression\n\nThere are two types of linear regression, Simple linear regression and multiple linear regression. Our discussion in this series will be on simple linear regression using R.\n\n## [**Assumptions of Simple Linear Regression**]{style=\"color: #2C6D26;\"}\n\nThe assumptions of simple linear regressions are:\n\n1.  **L**inearity: Ensure there is a linear relationship between the independent (X) and dependent variable(Y), a straight line represents the line that best fits the data points.\n\n2.  **I**ndependence: The independent and dependent variables have a linear relationship. This indicates that when one variable changes, the other variable changes proportionately.\n\n3.  **N**ormality: The errors are normally distributed\n\n4.  **E**quality of variance: The variability of the response does not increase as the value of the predictor increases. Case Study\n\n**LINE** is a simple acroynm for remembering the assumptions of simple linear regression.\n\n## [**Example**]{style=\"color: #2C6D26;\"}\n\nIn this example, we will be using a dataset on medical insurance cost. The dataset consists of information about the insurance buyers such as age, sex, BMI (body mass index), number of children, smoking habits and region. These variables serve as independent features, while the medical charges represent the dependent feature. The goal is to predict the medical charges based on the age of the individual.\n\n### [**Install packages**]{style=\"color: #138d75;\"}\n\n```{r setup, warning=FALSE, message=FALSE}\ninstall.packages(\"tidyverse\") \ninstall.packages(\"readxl\") \n```\n\n### [**Load the installed packages**]{style=\"color: #138d75;\"}\n\n```{r, warning = FALSE, message = FALSE}\nlibrary(tidyverse) \nlibrary(readxl)\n```\n\n### [**Load the datasets**]{style=\"color: #138d75;\"}\n\n```{r, warning = FALSE, message = FALSE}\nmedical_cost <- read_csv(\"insurance.csv\")\n```\n\n## [**Data Exploration**]{style=\"color: #2C6D26;\"}\n\n### [ **List structure of the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\nstr(medical_cost)\n```\n\n### [ **Summary of the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\nsummary(medical_cost)\n```\n\n### [ **Check the names in the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\nnames(medical_cost)\n```\n\n### [ **Check the number of rows**]{style=\"color: #138d75;\"}\n\n```{r}\nnrow(medical_cost)\n```\n\n### [ **Check number of columns**]{style=\"color: #138d75;\"}\n\n```{r}\nncol(medical_cost)\n```\n\n### [ **See first 6 rows of the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\nhead(medical_cost)\n```\n\n### [ **Check the last 6 rows of the dataset**]{style=\"color: #138d75;\"}\n\n```{r}\ntail(medical_cost)\n```\n\n### [ **Rename sex variable to gender**]{style=\"color: #138d75;\"}\n\n```{r}\nmedical_cost <- medical_cost |>   \n  mutate(across(c(sex: region ), as.factor)) |>   \n  rename(gender = sex)\n```\n\n### [ **Check for missing values**]{style=\"color: #138d75;\"}\n\n```{r}\nsum(is.na(medical_cost))\n```\n\n### [ **Check for duplicates**]{style=\"color: #138d75;\"}\n\n```{r}\nsum(duplicated(medical_cost))\n```\n\nThere is one duplicate, so we drop the duplicate value and work with the unique values\n\n```{r} #Remove duplicates}\nmedical_cost <- medical_cost[!duplicated(medical_cost),]\n```\n\nThe dataset changes from 1338 to 1337 because the duplicate value has been removed.\n\nSince this is a simple linear regression, I will be checking how the age of a patient affects the hospital charges.\n\n### [ **Visualizing the distribution of the age variable**]{style=\"color: #138d75;\"}\n\n```{r}\nage_plot <- ggplot(medical_cost, aes(x = age)) +  \n  geom_histogram(fill = \"steelblue\", color = \"black\", bins = 10) +  \n  labs(title = \"Distribution of Age\", x = \"Age\", y = \"Frequency\")  \n\ninteractive_plot <- plotly::ggplotly(age_plot) \ninteractive_plot\n```\n\n## [ **Checking if it meets up the Assumptions**]{style=\"color:  #2C6D26;\"}\n\n### [ **1. Linearity**]{style=\"color: #138d75;\"}\n\n```{r}\nplot(charges ~ age, data = medical_cost)\n```\n\nThis shows the linearity of age against charges.\n\n### [ **2. Independence** ]{style=\"color: #138d75;\"}\n\n```{r}\ncor(medical_cost$age, medical_cost$charges)  \n```\n\nThe correlation between age and charges is 0.3 which is not close to 1 or -1. This shows that the variables are independent of each other.\n\n**3. Normality and Homoscedasticity will be tested after fitting the model.**\n\n### [ **Fitting the regression model** ]{style=\"color: #138d75;\"}\n\n```{r}\nmodel <- lm(charges ~ age, data = medical_cost)\nmodel\n```\n\n```{r}\nsummary(model)\n```\n\n```{r}\nplot(model)\n```\n\nThe Q-Q residuals shows non-normality of the residuals.Hence, the dependent variable will be transformed to log to see if it will improve the normality of the residuals.\n\n```{r}\nmodel2 <- lm(log(charges) ~ age, data = medical_cost) \nmodel2\n```\n\n```{r}\nsummary(model2)\n```\n\nThe estimated effect of age on charges is 0.034. This means that for every one unit increase in age, the charges increases by 0.034. The p-value is less than 0.05 which means that the effect of age on charges is statistically significant. The R-squared value is 0.09 which means that 9% of the variation in charges can be explained by age. The standard error of the estimate is 0.1, with t value of 22.65 which means that the model is a good fit.\n\n```{r}\nplot(model2)\n```\n\nThe Residual vs Fitted shows that the residuals are homoscedastic and linear, and the Q-Q residuals shows that the residuals are normally distributed.\n\nTherefore, fitting the regression model with the log of charges is a better fit. The regression equation is given as: Charges = 0.034\\*age + 7.5\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"toc-depth":3,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","editor":"visual","theme":"cosmo","title":"<p style=\"color:black,text-align:center\">Simple Linear Regresson</p>","author":"Daniella Ojekere","toc-location":"right","toc-title":"Outline","toc_float":null,"collapsed":true,"smooth_scroll":true,"code_folding":"show"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}